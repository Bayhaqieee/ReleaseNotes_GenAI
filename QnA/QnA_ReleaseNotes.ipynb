{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyb0HoT0Bx5R54TjK6j8Op"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "QnzWZP1uaLvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "M6lw15RXaESJ"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain-openai langchain-community beautifulsoup4 faiss-cpu selenium selenium-wire undetected-chromedriver blinker==1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "nvtASy-BsMCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from dateutil.parser import parse as parse_date\n",
        "from langchain.docstore.document import Document\n",
        "from google.colab import userdata\n",
        "from seleniumwire import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException"
      ],
      "metadata": {
        "id": "uyuDr00tsNa_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config. Environment"
      ],
      "metadata": {
        "id": "MMX6KjS8aQ0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.docstore.document import Document\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get('AZURE_OPENAI_API_KEY')\n",
        "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "    os.environ[\"AZURE_OPENAI_API_VERSION\"] = userdata.get('OPENAI_API_VERSION')\n",
        "    os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"] = userdata.get('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME')\n",
        "    os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = userdata.get('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME')\n",
        "    print(\"Azure credentials loaded successfully from Colab Secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load secrets. Please ensure you have added all required keys to the Colab Secrets manager. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnV25zLzaSz0",
        "outputId": "0989168b-3788-4a0d-9967-aeafb663488e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azure credentials loaded successfully from Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Scraping"
      ],
      "metadata": {
        "id": "wLJyu2DZbESm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URLs for the release notes\n",
        "URLS = {\n",
        "    \"simplidots\": \"https://fitur-sap.simplidots.id/\",\n",
        "    \"langflow\": \"https://api.github.com/repos/langflow-ai/langflow/releases\",\n",
        "    \"anthropic\": \"https://docs.anthropic.com/en/release-notes/api\",\n",
        "    \"chatgpt\": \"https://help.openai.com/en/articles/6825453-chatgpt-release-notes\"\n",
        "}"
      ],
      "metadata": {
        "id": "IPM5O2f4bt5E"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q selenium undetected-chromedriver\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y chromium-chromedriver\n",
        "!sudo cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJoZnREjgzeQ",
        "outputId": "2b61f0a4-a548-44b0-f5e8-c3847e399ff2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to r2u.stat.i\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headless Chrome Setup"
      ],
      "metadata": {
        "id": "7OUP8igdg8PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "\n",
        "# Langchain-like Document stub\n",
        "class Document:\n",
        "    def __init__(self, page_content, metadata):\n",
        "        self.page_content = page_content\n",
        "        self.metadata = metadata"
      ],
      "metadata": {
        "id": "2myERNeHg-xq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Scraper"
      ],
      "metadata": {
        "id": "bFqOCN13bn6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GitHub Scraper"
      ],
      "metadata": {
        "id": "FLrs-C7ybp_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_github_releases(api_url):\n",
        "    \"\"\"\n",
        "    Scrapes GitHub releases and returns a list of Document objects,\n",
        "    each with its content and release date in the metadata.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    try:\n",
        "        response = requests.get(f\"{api_url}?per_page=15\", timeout=15)\n",
        "        response.raise_for_status()\n",
        "        releases = response.json()\n",
        "        for release in releases:\n",
        "            content = f\"## {release.get('name', 'Untitled Release')}\\n\\n{release.get('body', 'No description.')}\"\n",
        "\n",
        "            # Get the release date directly from the API response\n",
        "            release_date = release.get('published_at', '')\n",
        "\n",
        "            # Create a Document for each release\n",
        "            doc = Document(\n",
        "                page_content=content,\n",
        "                metadata={\n",
        "                    \"source\": \"https://github.com/langflow-ai/langflow/releases\",\n",
        "                    \"release_date\": release_date.split('T')[0] if release_date else 'unknown' # Format as YYYY-MM-DD\n",
        "                }\n",
        "            )\n",
        "            documents.append(doc)\n",
        "        return documents\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching GitHub releases from {api_url}: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "BAJG_vazbFUL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimpliDots Selenium + Link Crawler Scraper"
      ],
      "metadata": {
        "id": "mJV9aw_7jz0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urljoin\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException\n",
        "\n",
        "def scrape_simplidots_with_selenium(base_url, max_depth=2):\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    visited = set()\n",
        "    result_texts = []\n",
        "\n",
        "    def crawl(url, depth):\n",
        "        if depth > max_depth or url in visited:\n",
        "            return\n",
        "        print(f\"Crawling (depth {depth}): {url}\")\n",
        "        visited.add(url)\n",
        "        try:\n",
        "            driver.get(url)\n",
        "            wait_selector = \"main.page-has-toc\"\n",
        "            WebDriverWait(driver, 15).until(\n",
        "                EC.presence_of_element_located((By.CSS_SELECTOR, wait_selector))\n",
        "            )\n",
        "\n",
        "            # Use the same selector to find the element\n",
        "            content = driver.find_element(By.CSS_SELECTOR, wait_selector).text.strip()\n",
        "            if content:\n",
        "                result_texts.append(f\"URL: {url}\\n\\n{content}\")\n",
        "\n",
        "            links_to_visit = []\n",
        "            anchors = driver.find_elements(By.TAG_NAME, \"a\")\n",
        "            for a in anchors:\n",
        "                try:\n",
        "                    href = a.get_attribute(\"href\")\n",
        "                    if href and href.startswith(base_url) and href not in visited:\n",
        "                        links_to_visit.append(href)\n",
        "                except StaleElementReferenceException:\n",
        "                    continue\n",
        "\n",
        "            for link in links_to_visit:\n",
        "                crawl(link, depth + 1)\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(f\"Timeout waiting for content on {url}\")\n",
        "            driver.save_screenshot(f\"timeout_on_{url.replace('/', '_')}.png\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to crawl {url}: {e}\")\n",
        "\n",
        "    try:\n",
        "        crawl(base_url, 1) # Start crawling from depth 1\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    return \"\\n\\n---\\n\\n\".join(result_texts)"
      ],
      "metadata": {
        "id": "XuCCa6Qlj6-W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anthropic Selenium Scraper"
      ],
      "metadata": {
        "id": "FhaTDi0xiBYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def scrape_anthropic_with_selenium(url):\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        driver.implicitly_wait(10)\n",
        "        time.sleep(15)  # wait for full load\n",
        "\n",
        "        body = driver.find_element(By.TAG_NAME, \"body\")\n",
        "        return body.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error using Selenium for Anthropic release notes: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        driver.quit()"
      ],
      "metadata": {
        "id": "K_wXEkhJiEce"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute Scraping"
      ],
      "metadata": {
        "id": "Bx2iILZhbx7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Execute Scraping Cell - UPDATED ###\n",
        "\n",
        "print(\"Starting data scraping...\")\n",
        "all_documents = []\n",
        "\n",
        "# SimpliDOTS via Selenium\n",
        "simplidots_text = scrape_simplidots_with_selenium(URLS[\"simplidots\"], max_depth=2)\n",
        "if simplidots_text:\n",
        "    # We will process the SimpliDOTS text blob later\n",
        "    all_documents.append(Document(page_content=simplidots_text, metadata={\"source\": URLS[\"simplidots\"]}))\n",
        "    print(f\"Scraped SimpliDOTS: {len(simplidots_text)} characters\")\n",
        "else:\n",
        "    print(\"Failed to scrape SimpliDOTS.\")\n",
        "\n",
        "# Langflow - now returns a list of documents\n",
        "langflow_docs = scrape_github_releases(URLS[\"langflow\"])\n",
        "if langflow_docs:\n",
        "    all_documents.extend(langflow_docs) # Use extend to add all items from the list\n",
        "    print(f\"Scraped Langflow: {len(langflow_docs)} release documents\")\n",
        "else:\n",
        "    print(\"Failed to scrape Langflow.\")\n",
        "\n",
        "# Anthropic via Selenium\n",
        "anthropic_text = scrape_anthropic_with_selenium(URLS[\"anthropic\"])\n",
        "if anthropic_text:\n",
        "    all_documents.append(Document(page_content=anthropic_text, metadata={\"source\": URLS[\"anthropic\"]}))\n",
        "    print(f\"Scraped Anthropic: {len(anthropic_text)} characters\")\n",
        "else:\n",
        "    print(\"Failed to scrape Anthropic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGC0ZSIxbzZj",
        "outputId": "6c333705-f9c0-47fb-9cbe-5b0f5294ef18"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data scraping...\n",
            "Crawling (depth 1): https://fitur-sap.simplidots.id/\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/live-mode-kini-dilengkapi-opsi-reset-atau-tidak-reset-data-31-juli-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/beta-integrasi-sales-invoice-simplidots-x-accurate-online-17-juli-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/perbaikan-pemilihan-gudang-pada-buat-sales-invoice-11-juli-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/penambahan-fitur-collection-03-july-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/new-feature-tanya-ai\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/penambahan-fitur-customer-limit-19-may-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/penambahan-fitur-log-activity-pengaturan-quantity-jam-mulai-dan-akhir-promo-30-april-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/penambahan-fitur-edit-warehouse-and-bulk-transfer-stock-25-march-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/penambahan-fitur-impor-dan-ekspor-stok-20-march-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/custom-mapping-delivery-summary-ds-03-march-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/open-api-stock-dan-unit-03-march-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/update-mengenai-coretax-format-xml-ppn-12-phase-2\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/update-mengenai-coretax-format-xml-ppn-11-phase-1\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/penambahan-fitur-return-pada-smh-15-january-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/updates-mengenai-ppn-12\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-notifikasi-pada-smh-nov-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-customer-stock-berdasarkan-product-focus-09-oct-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-edit-delivery-summary-10-sept-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-e-faktur-11-sept-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-tampilan-pada-smart-portal-x-sap-28-oct-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-bi-smart-portal-x-sap-28-oct-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-pada-menu-sales-invoice-smh-05-sept-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-dan-pembaharuan-pada-menu-sales-invoice-2-sept-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-kolom-pada-hasil-export-si-sales-invoice-29-aug-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-print-dokumen-27-aug-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-open-api-sap-simplidots-31-july-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-generate-invoice-pada-sales-order-dan-fitur-cancel-si-24-july-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-marketing-banner-info-pada-halaman-registrasi-03-july-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-default-setting-pada-smh-27-june-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-switch-tenant-untuk-multi-tenants-di-smh-28-may-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-pada-manajemen-rute-kunjungan-08-may-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-menu-produk-pada-smh-02-may-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-menu-daily-visit-and-dashboard-pada-aplikasi-supervision-22-april-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/pembaharuan-menu-customer-pada-sales-management-hub-smh-17-mar-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-promo-diskon-kuantitas-and-nominal-bertingkat-06-maret-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-fitur-brand-pada-produk-19-feb-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/adjustment-pada-daily-visit-table-and-daily-visit-map-smh-07-feb-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-reset-route-pada-sales-management-hub-smh-23-januari-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/penambahan-report-sales-invoice-laporan-faktur-12-januari-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2024/adjustment-pada-role-group-default-10-januari-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/adjustment-manual-delivery-summary-and-infinite-fleet-27-desember-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-marketing-banner-info-pada-halaman-login-22-desember-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/adjustment-pada-top-bar-responsive-on-tablet-and-mobile-15-desember-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-fitur-purchase-pembelian-pada-smh-15-november-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/adjustment-pada-tampilan-top-bar-smh-19-oct-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/adjustment-pada-tampilan-sales-order-smh-25-sept-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/adjustment-pada-daily-visit-map-geografis-kunjungan-22-sept-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/adjustment-pada-minimum-akses-role-supervisor-06-sept-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-pop-up-pengumuman-simplidots-di-aplikasi-sfa-dan-canvass-23-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-fitur-price-list-default-pada-sales-order-di-smh-11-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-fitur-ekspor-sales-order-ke-.txt-file-extension-pada-smh-03-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/proteksi-jika-terdapat-perubahan-unit-produk-yang-telah-memiliki-transaksi-pada-smh-01-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-fitur-integrasi-stok-dari-antzman-ke-sap\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2023/penambahan-fitur-filter-updated-at-pada-sales-order-27-june-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.2.7-26-march-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.2.6-february-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/penambahan-tampilan-peta-sebelum-check-in-26-jan-2025\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.1.4-26-dec-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/sfa-new-sales-force-automation\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.1.2-06-nov-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.1.1-31-oct-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.0.12-02-sept-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-sfa-versi-3.0.10-23-aug-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-fitur-promo-pada-sfa-versi-2.17.0-17-july-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/sfa/fitur-pada-sfa-sales-force-automation/pembaharuan-tampilan-and-fitur-baru-pada-aplikasi-sfa-sales-force-automation-10-june-2024\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/canvass/fitur-pada-canvass\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/canvass/fitur-pada-canvass/penambahan-dan-perbaikan-fitur-pada-canvass-versi-1.2.1-03-july-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/canvass/fitur-pada-canvass/penambahan-fitur-dan-perbaikan-pada-canvass-12-june-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization/adjustment-tampilan-peta-dan-fitur-filter-pada-rekap-surat-jalan-delivery-summary-8-nov-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization/penambahan-fitur-filter-customer-fleet-pada-delivery-summary\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization/penambahan-fitur-cancel-batal-do-ds-dan-status-ds-pada-ro-21-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization/pembaharuan-fitur-import-do-surat-jalan-pada-ro-14-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization/fitur-laporan-delivery-order-delivery-summary-pada-smart-portal-07-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/route-optimization/fitur-pada-ro-route-optimization/penambahan-fitur-pada-route-optimization-ro-17-july-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smart-portal/smart-portal-distributor\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smart-portal/smart-portal-distributor/fitur-laporan-delivery-order-delivery-summary-pada-smart-portal-07-aug-2023\n",
            "Crawling (depth 2): https://fitur-sap.simplidots.id/smh\n",
            "Scraped SimpliDOTS: 402366 characters\n",
            "Scraped Langflow: 15 release documents\n",
            "Scraped Anthropic: 12752 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if simplidots_text:\n",
        "    words = simplidots_text.split()\n",
        "    display(\" \".join(words[:1000]))\n",
        "else:\n",
        "    display(\"simplidots text was not scraped successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "mXqNy7pCkVun",
        "outputId": "0f1a66de-ae29-4b9a-d419-0c091a7bf782"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'URL: https://fitur-sap.simplidots.id/ Copy SMH Fitur pada SMH (Sales Management Hub) Temukan penjelasan mengenai fitur-fitur terbaru di 2024 2023 2025 Next 2025 Last updated 2 months ago Was this helpful? --- URL: https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025 Copy SMH FITUR PADA SMH (SALES MANAGEMENT HUB) 2025 üîú Live Mode Kini Dilengkapi Opsi Reset atau Tidak Reset Data - 31 Juli 2025 üî• [Beta] - Integrasi Sales Invoice SimpliDOTS x Accurate Online - [17 Juli 2025] üî• Perbaikan Pemilihan Gudang pada Buat Sales Invoice - [11 Juli 2025] üî• Penambahan Fitur Collection - [03 July 2025] New Feature: Tanya AI üöÄ Penambahan Fitur Customer Limit - [19 May 2025] üöÄ Penambahan Fitur Log Activity, Pengaturan Quantity, Jam Mulai dan Akhir Promo - [30 April 2025] üöÄ Penambahan Fitur Edit Warehouse & Bulk Transfer Stock - [25 March 2025] üöÄ Penambahan Fitur Impor dan Ekspor Stok - [20 March 2025] üöÄ Custom Mapping Delivery Summary (DS) - [03 March 2025] üöÄ Open API Stock dan Unit - [03 March 2025] üöÄ Update Mengenai Coretax Format XML PPN 12%- [Phase 2] üöÄ Update Mengenai Coretax Format XML PPN 11% - [Phase 1] üöÄ Penambahan Fitur Return pada SMH - [15 January 2025] Previous Fitur pada SMH (Sales Management Hub) Next Live Mode Kini Dilengkapi Opsi Reset atau Tidak Reset Data - 31 Juli 2025 Was this helpful? --- URL: https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/live-mode-kini-dilengkapi-opsi-reset-atau-tidak-reset-data-31-juli-2025 Copy SMH FITUR PADA SMH (SALES MANAGEMENT HUB) 2025 üîú Live Mode Kini Dilengkapi Opsi Reset atau Tidak Reset Data - 31 Juli 2025 Halo, Kawan Simpli! Ada kabar gembira untukmu! Kami telah melakukan beberapa pembaruan penting untuk membuat penggunaan SimpliDOTS menjadi lebih lancar dan nyaman. Berikut ringkasan perubahan yang perlu Anda ketahui: Fitur Baru: Live Mode dengan Pilihan Reset Data atau Tidak Untuk meningkatkan pengalaman pengguna, SimpliDOTS menghadirkan pembaruan pada proses aktivasi Live Mode. Sebelumnya, banyak pengguna secara tidak sengaja menghapus seluruh data penting saat masih dalam masa uji coba (free trial) karena tidak memahami dampak dari fitur reset data. Kini, proses ini menjadi lebih aman, transparan, dan dapat dilakukan secara mandiri tanpa perlu bantuan tim support. üîß Saat mengaktifkan Live Mode, Anda dapat memilih salah satu dari dua opsi berikut: Live tanpa Reset Data Pilihan ini cocok jika Anda ingin melanjutkan penggunaan SimpliDOTS dengan data yang sudah ada. Semua transaksi yang telah diinput selama masa trial akan tetap tersimpan. Live dengan Reset Data Gunakan opsi ini jika Anda ingin memulai dari awal. Semua data transaksi yang diinput saat testing akan dihapus secara permanen. Opsi ini ideal jika Anda ingin memulai sistem dengan data yang bersih. üîê Konfirmasi Tambahan untuk Mencegah Kesalahan Sebelum proses aktivasi dilanjutkan, sistem akan meminta Anda untuk mengetik ulang pernyataan konfirmasi yang muncul dalam pop-up. Langkah ini bertujuan untuk memastikan Anda benar-benar memahami tindakan yang diambil dan menghindari kehilangan data yang tidak disengaja. Selamat mencoba, Kawan Simpli! Jangan ragu untuk menghubungi tim Customer Success Kami jika ada pertanyaan atau memerlukan bantuan. Kami siap membantu, Kawan Simpli! Terima kasih telah memilih SimpliDOTS. Kami berkomitmen untuk terus meningkatkan experience Kawan Simpli dalam menggunakan SimpliDOTS. Salam Hangat - Androsim - Previous 2025 Next [Beta] - Integrasi Sales Invoice SimpliDOTS x Accurate Online - [17 Juli 2025] Last updated 4 hours ago Was this helpful? --- URL: https://fitur-sap.simplidots.id/smh/fitur-pada-smh-sales-management-hub/2025/beta-integrasi-sales-invoice-simplidots-x-accurate-online-17-juli-2025 Copy SMH FITUR PADA SMH (SALES MANAGEMENT HUB) 2025 üî• [Beta] - Integrasi Sales Invoice SimpliDOTS x Accurate Online - [17 Juli 2025] Halo, Kawan Simpli! Ada kabar gembira untukmu! Kami telah melakukan beberapa pembaruan penting untuk membuat penggunaan SimpliDOTS menjadi lebih lancar dan nyaman. Berikut ringkasan perubahan yang perlu Anda ketahui: Kami sedang dalam proses mengembangkan integrasi antara SimpliDOTS dan Accurate Online khusus untuk fitur Sales Invoice (Faktur Penjualan). Tujuannya adalah untuk mempermudah proses penagihan tanpa perlu input manual di dua tempat. üí° Versi ini masih BETA! Saat ini fitur belum sepenuhnya berjalan sempurna karena belum ada koneksi ke sistem pembayaran (Customer Payment) yang sedang kami kembangkan. Fitur ini kami rilis lebih awal dalam versi beta agar pengguna bisa mulai mencoba dan memberikan masukan. Dengan feedback dari Anda, kami dapat menyempurnakan integrasi ini agar lebih optimal ke depannya. Tampilan menu Integrasi Tampilan hasil Sinkron Integrasi ‚ú® Fitur yang Sudah Tersedia ‚úÖ Integrasi Data Faktur (Sales Invoice) ‚úÖ Notifikasi Gagal Sinkronisasi Sales Invoice ‚úÖ Integrasi Data Faktur (Sales Invoice) Data faktur kini dapat ditarik dari Accurate ke SimpliDOTS Sebaliknya, faktur juga bisa dikirim dari SimpliDOTS ke Accurate Fitur ini mendukung berbagai alur penjualan: Dari Sales Order langsung ke Sales Invoice Dari Sales Order ke Delivery Order, lalu ke Sales Invoice Atau transaksi penjualan langsung melalui Sales Invoice tanpa melalui tahapan order dan pengiriman Tampilan Sales Invoice di Accurate Tampilan hasil sync yang berhasil antara Accurate dan SimpiliDOTS memiliki Partner ID. ‚úÖ Notifikasi Gagal Sinkronisasi Sales Invoice Sekarang sistem akan otomatis menampilkan notifikasi jika terjadi kegagalan saat menarik data Sales Invoice antara SimpliDOTS dan Accurate. Notifikasi ini berguna untuk membantu Anda segera mengetahui dan menangani kendala yang muncul, seperti: Data yang duplikat Informasi yang belum lengkap Gangguan koneksi antar sistem Tampilan Notifikasi Tampilan informasi detail pada notifikasi ‚ö†Ô∏è Beberapa Hal yang Perlu Diperhatikan ‚ùó Status Pembayaran Belum Sepenuhnya Akurat ‚ùó Status Pembayaran Belum Sinkron Sepenuhnya Untuk saat ini, status pembayaran pada Sales Invoice di SimpliDOTS dan Accurate belum sepenuhnya terintegrasi. Artinya: Jika Anda mengirim tagihan dari SimpliDOTS ke Accurate, maka statusnya di Accurate akan selalu muncul sebagai ‚ÄúBelum Lunas‚Äù, meskipun sebenarnya sudah dibayar di SimpliDOTS. Tampilan Sales Invoice telah dibayar Tampilan hasil sync di Accurate akan terdeteksi sebagai belum lunas karena integrasi pembayaran SimpliDOTS masih dalam tahap perkembangan. Sebaliknya, jika Anda menarik tagihan dari Accurate ke SimpliDOTS, status di SimpliDOTS tetap akan terlihat ‚ÄúAktif‚Äù, walaupun di Accurate tagihan tersebut sudah lunas. Tampilan Sales Invoice di Accurate telah di bayar. Tampilan hasil sync di SimpliDOTS akan terdeteksi sebagai belum bayar karena integrasi pembayaran masih dalam tahap perkembangan. üìå Mengapa bisa terjadi? Karena integrasi dengan sistem pembayaran (CP) masih dalam tahap pengembangan. Untuk saat ini, informasi pelunasan belum bisa otomatis terbaca antar sistem. ‚ùó Penghapusan Tagihan Belum Sepenuhnya Dua Arah Saat ini, fitur penghapusan tagihan belum mendukung sinkronisasi dua arah: Jika Anda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if langflow_text:\n",
        "    words = langflow_text.split()\n",
        "    display(\" \".join(words[:1000]))\n",
        "else:\n",
        "    display(\"Langflow text was not scraped successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "QwHUxPi0jNiB",
        "outputId": "6492b4c9-d55e-4b5c-d553-5c12a379e764"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"## 1.5.0.post1 <!-- Release notes generated using configuration in .github/release.yml at 1.5.0.post1 --> ## What's Changed ### ‚ú® New Features * feat: Add dynamic theming support to WatsonxAI icon by @Cristhianzl in https://github.com/langflow-ai/langflow/pull/8935 * feat: jigsawstack bundle integration by @Khurdhula-Harshavardhan in https://github.com/langflow-ai/langflow/pull/8832 * feat: enhance DataFrame Operations component with contains filter and modern UI by @rodrigosnader in https://github.com/langflow-ai/langflow/pull/8838 * feat: add DataFrame output to Structured Output component by @rodrigosnader in https://github.com/langflow-ai/langflow/pull/8842 ### üêõ Bug Fixes * fix: Improve modal layout responsiveness and overflow handling by @Cristhianzl in https://github.com/langflow-ai/langflow/pull/8936 * fix: Improve flow export error handling and validation by @Cristhianzl in https://github.com/langflow-ai/langflow/pull/8943 * fix: make deletion of single file commit to DB, create tests for file deletion by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8953 * fix: update API Access codes to include only authenticated code by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8957 * fix: Ensure flow_id is not None before logging vertex build details by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8954 * fix: fix max height of template getting started cards by @mfortman11 in https://github.com/langflow-ai/langflow/pull/8964 * fix: clean edges of same type but different name when switching outputs, update color when deleting edges by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8959 * fix: Update file component description for accuracy by @erichare in https://github.com/langflow-ai/langflow/pull/8960 * fix: make mcp server component handle cache miss gracefully by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8966 * fix: make files be saved in unique path by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8965 * fix: add scroll to update components review dialog by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8983 * fix: improved better health check and stream URL check on MCP, improved JSON recognition by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8982 ### üìù Documentation Updates * docs: update nv-ingest component by @mendonk in https://github.com/langflow-ai/langflow/pull/8950 * docs: 1.5 release by @mendonk in https://github.com/langflow-ai/langflow/pull/8387 * docs: add required API key headers for 1.5 by @mendonk in https://github.com/langflow-ai/langflow/pull/8721 * docs: add windows desktop back for 1.5 release by @mendonk in https://github.com/langflow-ai/langflow/pull/8866 * docs: add windows related content by @mendonk in https://github.com/langflow-ai/langflow/pull/8903 * docs: how to add a missing dependency to langflow desktop by @mendonk in https://github.com/langflow-ai/langflow/pull/8942 * docs: add unix note to api pane by @mendonk in https://github.com/langflow-ai/langflow/pull/8951 * docs: docling integration by @mendonk in https://github.com/langflow-ai/langflow/pull/8939 * docs: remove duplicate intro text by @mendonk in https://github.com/langflow-ai/langflow/pull/8987 * docs: chatbot with files tutorial by @mendonk in https://github.com/langflow-ai/langflow/pull/8813 ### üõ† Maintenance Tasks * refactor: Extract single file download logic to custom hook by @Cristhianzl in https://github.com/langflow-ai/langflow/pull/8944 * refactor(auth): simplify flow retrieval by removing settings_service dependency by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8956 * refactor: update cache service type hints in MCPToolsComponent by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8975 * refactor: update imports and move functions out of MCPToolsComponent by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8976 ### Others * chore: release 1.5.0 by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8930 * chore: update package versions to include post-release tags by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8955 * chore: enable code guidelines in coderabbit configuration by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8958 * ci: update regex pattern for langflow-base dependency to support PEP 440 version suffixes by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8979 * ci: update nightly script to support other version operators by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8980 * templates: Update Vector Store RAG.json by @mendonk in https://github.com/langflow-ai/langflow/pull/8977 ## New Contributors * @Khurdhula-Harshavardhan made their first contribution in https://github.com/langflow-ai/langflow/pull/8832 **Full Changelog**: https://github.com/langflow-ai/langflow/compare/1.5.0...1.5.0.post1 --- ## 1.5.0 <!-- Release notes generated using configuration in .github/release.yml at refs/heads/release-1.5.0 --> ## What's Changed ### ‚ú® New Features * feat: deprecate processing components by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/7254 * feat: add rss component by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8134 * feat: New Web search component by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8135 * feat: Adds our first Cursor rules by @mfortman11 in https://github.com/langflow-ai/langflow/pull/7973 * feat: adds new Edit Details popover, removes flow menu, fixes nav alignment, adds new Flow Status overlay by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8087 * feat: Enhance API request component by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8070 * feat: add datastax components bundle by @erichare in https://github.com/langflow-ai/langflow/pull/8184 * feat: updated components header styling by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8085 * ref: SQL component by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8185 * feat: Loop uplift dataframe input and output by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8177 * feat: News Search Component by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8190 * feat: add llm keywords to language model base by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8115 * feat: New Search Bundle by @Yukiyukiyeah in https://github.com/langflow-ai/langflow/pull/8146 * feat: implement web app manifest for progressive web app functionality by @Cristhianzl in https://github.com/langflow-ai/langflow/pull/8216 * feat: Add Composio GitHub component by @abhishekpatil4 in https://github.com/langflow-ai/langflow/pull/7640 * Feat: move other tools to different folders by @Yukiyukiyeah in https://github.com/langflow-ai/langflow/pull/8164 * feat: Outputs UX improvements by @deon-sanchez in https://github.com/langflow-ai/langflow/pull/8131 * feat: changed tweaks into input schema and enabled persistence by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8235 * feat: add export option to deploy dropdown by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8221 * feat: add models category by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8231 * feat: Add customizable chat input and file upload components by @Cristhianzl in https://github.com/langflow-ai/langflow/pull/8237 * feat: Add async output resolution with caching and ordered processing by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/7487 * feat: create an IO Category by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8229 * ref: URL and File components with Dataframe output by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/8117 * Ref: LLMRouterComponent with Advanced OpenRouter Integration by @raphaelchristi in https://github.com/langflow-ai/langflow/pull/8220 * feat: add one click install to mcp servers on specific clients by @lucaseduoli in https://github.com/langflow-ai/langflow/pull/8271 * feat: add convert component with dynamic output support by @edwinjosechittilappilly in https://github.com/langflow-ai/langflow/pull/7773 * ci(docker): update Buildx setup to use BuildKit container backend by @ogabrielluiz in https://github.com/langflow-ai/langflow/pull/8320 * feat: Add Composio Outlook component by @abhishekpatil4 in https://github.com/langflow-ai/langflow/pull/7987 * feat: Update components input/output display name and descriptions by @Yukiyukiyeah in https://github.com/langflow-ai/langflow/pull/8284 * feat: Add Google as an option for genai by @erichare in https://github.com/langflow-ai/langflow/pull/8358 * feat: Add Cleanlab's AI Reliability Bundle to Langflow by @cmauck10 in https://github.com/langflow-ai/langflow/pull/8049 * feat: combine chat history and chat store into a CRUD component by @Yukiyukiyeah in https://github.com/langflow-ai/langflow/pull/8323 * feat: NV-ingest high resolution extraction and infographics content extraction by @maheshrajamani in https://github.com/langflow-ai/langflow/pull/8315 * feat: change smart function title, icon and desc by @Yukiyukiyeah in https://github.com/langflow-ai/langflow/pull/8405 * feat: enhance OutputComponent dropdown functionality and styling by @deon-sanchez in https://github.com/langflow-ai/langflow/pull/8458 * Fix: chat memory store issue and fix output types by @Yukiyukiyeah in https://github.com/langflow-ai/langflow/pull/8463 * feat: add servers persistence to MCP connection component, add MCP connections settings\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if anthropic_text:\n",
        "    words = anthropic_text.split()\n",
        "    display(\" \".join(words[:1000]))\n",
        "else:\n",
        "    display(\"Anthropic text was not scraped successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "OUdJCHETjBlL",
        "outputId": "511a1b7e-5e10-4207-fb7f-595931b43363"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Anthropic home page English Search... Navigation Release Notes API RELEASE NOTES API Copy page Follow along with updates across Anthropic‚Äôs API and Developer Console. July 28, 2025 We‚Äôve released text_editor_20250728, an updated text editor tool that fixes some issues from the previous versions and adds an optional max_characters parameter that allows you to control the truncation length when viewing large files. July 24, 2025 We‚Äôve increased rate limits for Claude Opus 4 on the Anthropic API to give you more capacity to build and scale with Claude. For customers with usage tier 1-4 rate limits, these changes apply immediately to your account - no action needed. July 21, 2025 We‚Äôve retired the Claude 2.0, Claude 2.1, and Claude Sonnet 3 models. All requests to these models will now return an error. Read more in our documentation. July 17, 2025 We‚Äôve increased rate limits for Claude Sonnet 4 on the Anthropic API to give you more capacity to build and scale with Claude. For customers with usage tier 1-4 rate limits, these changes apply immediately to your account - no action needed. July 3, 2025 We‚Äôve launched search result content blocks in beta, enabling natural citations for RAG applications. Tools can now return search results with proper source attribution, and Claude will automatically cite these sources in its responses - matching the citation quality of web search. This eliminates the need for document workarounds in custom knowledge base applications. Learn more in our search results documentation. To enable this feature, use the beta header search-results-2025-06-09. June 30, 2025 We announced the deprecation of the Claude Opus 3 model. Read more in our documentation. June 23, 2025 Console users with the Developer role can now access the Cost page. Previously, the Developer role allowed access to the Usage page, but not the Cost page. June 11, 2025 We‚Äôve launched fine-grained tool streaming in public beta, a feature that enables Claude to stream tool use parameters without buffering / JSON validation. To enable fine-grained tool streaming, use the beta header fine-grained-tool-streaming-2025-05-14. May 22, 2025 We‚Äôve launched Claude Opus 4 and Claude Sonnet 4, our latest models with extended thinking capabilities. Learn more in our Models & Pricing documentation. The default behavior of extended thinking in Claude 4 models returns a summary of Claude‚Äôs full thinking process, with the full thinking encrypted and returned in the signature field of thinking block output. We‚Äôve launched interleaved thinking in public beta, a feature that enables Claude to think in between tool calls. To enable interleaved thinking, use the beta header interleaved-thinking-2025-05-14. We‚Äôve launched the Files API in public beta, enabling you to upload files and reference them in the Messages API and code execution tool. We‚Äôve launched the Code execution tool in public beta, a tool that enables Claude to execute Python code in a secure, sandboxed environment. We‚Äôve launched the MCP connector in public beta, a feature that allows you to connect to remote MCP servers directly from the Messages API. To increase answer quality and decrease tool errors, we‚Äôve changed the default value for the top_p nucleus sampling parameter in the Messages API from 0.999 to 0.99 for all models. To revert this change, set top_p to 0.999. Additionally, when extended thinking is enabled, you can now set top_p to values between 0.95 and 1. We‚Äôve moved our Go SDK from beta to GA. We‚Äôve included minute and hour level granularity to the Usage page of Console alongside 429 error rates on the Usage page. May 21, 2025 We‚Äôve moved our Ruby SDK from beta to GA. May 7, 2025 We‚Äôve launched a web search tool in the API, allowing Claude to access up-to-date information from the web. Learn more in our web search tool documentation. May 1, 2025 Cache control must now be specified directly in the parent content block of tool_result and document.source. For backwards compatibility, if cache control is detected on the last block in tool_result.content or document.source.content, it will be automatically applied to the parent block instead. Cache control on any other blocks within tool_result.content and document.source.content will result in a validation error. April 9th, 2025 We launched a beta version of the Ruby SDK March 31st, 2025 We‚Äôve moved our Java SDK from beta to GA. We‚Äôve moved our Go SDK from alpha to beta. February 27th, 2025 We‚Äôve added URL source blocks for images and PDFs in the Messages API. You can now reference images and PDFs directly via URL instead of having to base64-encode them. Learn more in our vision documentation and PDF support documentation. We‚Äôve added support for a none option to the tool_choice parameter in the Messages API that prevents Claude from calling any tools. Additionally, you‚Äôre no longer required to provide any tools when including tool_use and tool_result blocks. We‚Äôve launched an OpenAI-compatible API endpoint, allowing you to test Claude models by changing just your API key, base URL, and model name in existing OpenAI integrations. This compatibility layer supports core chat completions functionality. Learn more in our OpenAI SDK compatibility documentation. February 24th, 2025 We‚Äôve launched Claude Sonnet 3.7, our most intelligent model yet. Claude Sonnet 3.7 can produce near-instant responses or show its extended thinking step-by-step. One model, two ways to think. Learn more about all Claude models in our Models & Pricing documentation. We‚Äôve added vision support to Claude Haiku 3.5, enabling the model to analyze and understand images. We‚Äôve released a token-efficient tool use implementation, improving overall performance when using tools with Claude. Learn more in our tool use documentation. We‚Äôve changed the default temperature in the Console for new prompts from 0 to 1 for consistency with the default temperature in the API. Existing saved prompts are unchanged. We‚Äôve released updated versions of our tools that decouple the text edit and bash tools from the computer use system prompt: bash_20250124: Same functionality as previous version but is independent from computer use. Does not require a beta header. text_editor_20250124: Same functionality as previous version but is independent from computer use.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion"
      ],
      "metadata": {
        "id": "uye-7TK4b6x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunking Process"
      ],
      "metadata": {
        "id": "yCy1krb6b_iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "print(\"Chunking documents...\")\n",
        "chunked_docs = text_splitter.split_documents(all_documents)\n",
        "print(f\"Documents chunked successfully. Total chunks: {len(chunked_docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXCmxeZDb8_X",
        "outputId": "8fd176d7-7368-49eb-da1f-21a3b4aa57e8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunking documents...\n",
            "Documents chunked successfully. Total chunks: 602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "RXyNSkb0sABw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Text Cleaning Function"
      ],
      "metadata": {
        "id": "cD-ekmHltih2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Cleans a single string of text.\"\"\"\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
        "    text = '\\n'.join(line.strip() for line in text.split('\\n'))\n",
        "    artifacts = [\n",
        "        \"Was this helpful?\", \"Powered by GitBook\", \"Copy\", \"Next\", \"Previous\",\n",
        "        \"Last updated\", \"ago\", \"hours\", \"minutes\"\n",
        "    ]\n",
        "    for artifact in artifacts:\n",
        "        text = text.replace(artifact, \"\")\n",
        "    # Remove any line that is just a year (e.g., '2025', '2024')\n",
        "    text = re.sub(r'^\\d{4}$', '', text, flags=re.MULTILINE)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "sF8XQHJ6tmR-"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format Release Date"
      ],
      "metadata": {
        "id": "EyNUOTePtobW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_format_date(text):\n",
        "    \"\"\"\n",
        "    Finds a date, translates Indonesian months, and returns a formatted string.\n",
        "    \"\"\"\n",
        "    # Mapping for Indonesian to English months\n",
        "    month_map = {\n",
        "        'januari': 'january', 'februari': 'february', 'maret': 'march', 'april': 'april',\n",
        "        'mei': 'may', 'juni': 'june', 'juli': 'july', 'agustus': 'august',\n",
        "        'september': 'september', 'oktober': 'october', 'november': 'november', 'desember': 'december'\n",
        "    }\n",
        "\n",
        "    # Regex to find dates with either English or Indonesian month names\n",
        "    date_pattern = r\"(?i)(\\d{1,2}\\s+(?:Jan(?:uari)?|Feb(?:ruari)?|Mar(?:et)?|Apr(?:il)?|Mei|Jun(?:i)?|Jul(?:i)?|Agu(?:stus)?|Sep(?:tember)?|Okt(?:ober)?|Nov(?:ember)?|Des(?:ember)?)\\s+\\d{4}|(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\s+\\d{1,2}(?:st|nd|rd|th)?(?:,)?\\s+\\d{4})\"\n",
        "\n",
        "    match = re.search(date_pattern, text)\n",
        "    if match:\n",
        "        try:\n",
        "            date_str = match.group(0).lower()\n",
        "            # Translate month if it's Indonesian\n",
        "            for indo, eng in month_map.items():\n",
        "                date_str = date_str.replace(indo, eng)\n",
        "\n",
        "            # Parse the cleaned date string and format it\n",
        "            parsed_date = parse_date(date_str)\n",
        "            return parsed_date\n",
        "        except (ValueError, TypeError):\n",
        "            return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "niXT_9zBsCLk"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initiate Preprocessing"
      ],
      "metadata": {
        "id": "qmw30o49tvZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting data preprocessing and cleaning...\")\n",
        "\n",
        "# First, chunk the documents that haven't been processed yet (SimpliDots, Anthropic, ChatGPT)\n",
        "docs_to_chunk = [doc for doc in all_documents if 'release_date' not in doc.metadata]\n",
        "chunked_non_github_docs = text_splitter.split_documents(docs_to_chunk)\n",
        "\n",
        "# Start our final processed list with the already-good GitHub docs\n",
        "processed_docs = [doc for doc in all_documents if 'release_date' in doc.metadata]\n",
        "\n",
        "# Now, process the newly chunked documents\n",
        "current_date_for_section = None\n",
        "last_source = None\n",
        "\n",
        "for doc in chunked_non_github_docs:\n",
        "    # Reset date when we switch to a new source file\n",
        "    if doc.metadata['source'] != last_source:\n",
        "        current_date_for_section = None\n",
        "        last_source = doc.metadata['source']\n",
        "\n",
        "    cleaned_content = clean_text(doc.page_content)\n",
        "    if len(cleaned_content) < 50:\n",
        "        continue\n",
        "\n",
        "    extracted_date = extract_and_format_date(cleaned_content)\n",
        "    if extracted_date:\n",
        "        current_date_for_section = extracted_date\n",
        "\n",
        "    if current_date_for_section:\n",
        "        doc.metadata['release_date'] = current_date_for_section.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        doc.metadata['release_date'] = 'unknown'\n",
        "\n",
        "    doc.page_content = cleaned_content\n",
        "    processed_docs.append(doc)\n",
        "\n",
        "print(f\"Preprocessing complete. Total processed documents/chunks: {len(processed_docs)}\")\n",
        "\n",
        "# Sort all documents by date, newest first\n",
        "processed_docs.sort(key=lambda x: x.metadata.get('release_date', '0000-00-00'), reverse=True)\n",
        "\n",
        "print(\"\\nExample of a newly processed chunk's metadata:\")\n",
        "# Find the first non-GitHub doc to show a successful example\n",
        "for doc in processed_docs:\n",
        "    if \"github\" not in doc.metadata[\"source\"]:\n",
        "        print(doc.metadata)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O46KqA60tur_",
        "outputId": "30deef40-6c6a-452e-da59-8b5f566440e0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data preprocessing and cleaning...\n",
            "Preprocessing complete. Total processed documents/chunks: 400\n",
            "\n",
            "Example of a newly processed chunk's metadata:\n",
            "{'source': 'https://fitur-sap.simplidots.id/', 'release_date': '2025-07-31'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Embedding"
      ],
      "metadata": {
        "id": "sfddN1-9cfAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import math\n",
        "import time\n",
        "\n",
        "print(\"Initializing Azure OpenAI Embeddings model...\")\n",
        "azure_embeddings = AzureOpenAIEmbeddings(\n",
        "    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
        "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
        ")\n",
        "print(\"Embedding model initialized.\")\n",
        "\n",
        "# Batch processing and embedding\n",
        "batch_size = 1000\n",
        "total_chunks = len(chunked_docs)\n",
        "vector_store = None # Initialize vector_store to None\n",
        "\n",
        "if total_chunks > 0:\n",
        "    num_batches = math.ceil(total_chunks / batch_size)\n",
        "    print(f\"\\nStarting embedding process in {num_batches} batches of size {batch_size}...\")\n",
        "\n",
        "    for i in range(0, total_chunks, batch_size):\n",
        "        batch_number = (i // batch_size) + 1\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Get the current batch of documents\n",
        "        batch_docs = chunked_docs[i:i + batch_size]\n",
        "        print(f\"  - Processing Batch {batch_number}/{num_batches} ({len(batch_docs)} chunks)...\")\n",
        "\n",
        "        if vector_store is None:\n",
        "            # For the first batch, create the FAISS index\n",
        "            vector_store = FAISS.from_documents(batch_docs, azure_embeddings)\n",
        "            print(\"    - Initial FAISS index created.\")\n",
        "        else:\n",
        "            # For subsequent batches, add them to the existing index\n",
        "            vector_store.add_documents(batch_docs)\n",
        "            print(\"    - Batch added to existing FAISS index.\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"  - Batch {batch_number} finished in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    print(\"\\nAll batches have been processed and embedded.\")\n",
        "\n",
        "    # Save the completed vector store\n",
        "    vector_store.save_local(\"faiss_index_release_notes\")\n",
        "    print(\"Vector store saved to Colab's local directory: 'faiss_index_release_notes'\")\n",
        "else:\n",
        "    print(\"No documents were chunked. Skipping embedding process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4hP5n4rcf-0",
        "outputId": "7920f127-56b6-4d96-9910-328a22325712"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Azure OpenAI Embeddings model...\n",
            "Embedding model initialized.\n",
            "\n",
            "Starting embedding process in 1 batches of size 1000...\n",
            "  - Processing Batch 1/1 (602 chunks)...\n",
            "    - Initial FAISS index created.\n",
            "  - Batch 1 finished in 6.97 seconds.\n",
            "\n",
            "All batches have been processed and embedded.\n",
            "Vector store saved to Colab's local directory: 'faiss_index_release_notes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize RAG System"
      ],
      "metadata": {
        "id": "8LEmLq62crvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize LLM"
      ],
      "metadata": {
        "id": "tlquOq0Jcyli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Explicitly get and set the variables\n",
        "azure_endpoint = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "azure_deployment = userdata.get('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME')\n",
        "api_key = userdata.get('AZURE_OPENAI_API_KEY')\n",
        "api_version = userdata.get('OPENAI_API_VERSION')\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    azure_deployment=azure_deployment,\n",
        "    api_key=api_key,\n",
        "    api_version=api_version,\n",
        "    model=f\"azure/{userdata.get('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME')}\"\n",
        ")\n",
        "\n",
        "print(\"LLM initialized.\")\n",
        "\n",
        "# Create a retriever from the vector store\n",
        "retriever = vector_store.as_retriever(search_kwargs={'k': 4})\n",
        "print(\"Retriever created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8OuXpE_cuaY",
        "outputId": "4371324e-01dc-4d31-e788-0871faefb561"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM initialized.\n",
            "Retriever created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Chain"
      ],
      "metadata": {
        "id": "q5iHuT-odDxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "rewrite_template = \"\"\"\n",
        "You are an expert query translator. Your task is to translate the user's question into a clean, direct English search query.\n",
        "Identify the key software names mentioned (like SimpliDots, LangFlow, etc.) and the user's core intent (e.g., \"latest updates\", \"new features\").\n",
        "Do NOT add any new technical concepts or topics that are not in the original question. Keep the query focused on the original's intent.\n",
        "\n",
        "Original Question:\n",
        "{question}\n",
        "\n",
        "Cleaned English Search Query:\n",
        "\"\"\"\n",
        "\n",
        "rewrite_prompt = PromptTemplate(\n",
        "    template=rewrite_template,\n",
        "    input_variables=[\"question\"],\n",
        ")\n",
        "\n",
        "# The rewriter chain itself\n",
        "query_rewriter = rewrite_prompt | llm | StrOutputParser()\n",
        "print(\"Constrained query rewriter chain created.\")\n",
        "\n",
        "\n",
        "# --- 2. Define the Main RAG Prompt ---\n",
        "# This prompt remains the same.\n",
        "prompt_template = \"\"\"\n",
        "You are an intelligent assistant for querying software release notes.\n",
        "Use only the following retrieved context to answer the user's question. If the question is in Indonesian, please answer in Indonesian.\n",
        "If you don't have enough information from the context for a specific topic, state that clearly for that topic and answer the rest.\n",
        "Do not make up information. Be concise and helpful.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# Helper function to format the retrieved documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(f\"Source: {doc.metadata.get('source', 'N/A')}\\nDate: {doc.metadata.get('release_date', 'N/A')}\\nContent: {doc.page_content}\" for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": query_rewriter | retriever | format_docs,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"Final RAG chain with constrained rewriting created. Ready to answer questions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyzdUiZNdEy4",
        "outputId": "c4425876-78c3-4a2a-c965-9e1cf02f93bc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constrained query rewriter chain created.\n",
            "Final RAG chain with constrained rewriting created. Ready to answer questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Testing"
      ],
      "metadata": {
        "id": "2A5NwDmsdPb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'rag_chain' in locals():\n",
        "    # --- Get user input for the query ---\n",
        "    query = input(\"Enter your query: \")\n",
        "    print(f\"Question: {query}\")\n",
        "\n",
        "    # You can also see what the rewriter does with your query:\n",
        "    rewritten_query = query_rewriter.invoke(query)\n",
        "    print(f\"Rewritten Query for Retrieval: {rewritten_query}\\n\")\n",
        "\n",
        "    # Invoke the full chain\n",
        "    answer = rag_chain.invoke(query)\n",
        "\n",
        "    print(\"\\nAnswer:\")\n",
        "    print(answer)\n",
        "else:\n",
        "    print(\"Cannot run tests because the RAG chain was not created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BaYUi7xdQ8L",
        "outputId": "fca06c92-6b8b-4391-cbd2-085e5922473b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: Hello, apa aja ya update SimpliDots ditahun 2025?\n",
            "Question: Hello, apa aja ya update SimpliDots ditahun 2025?\n",
            "Rewritten Query for Retrieval: SimpliDots 2025 updates\n",
            "\n",
            "\n",
            "Answer:\n",
            "Pada tahun 2025, update dari SimpliDOTS yang tersedia dalam konteks adalah:\n",
            "\n",
            "1. **[Beta] - Integrasi Sales Invoice SimpliDOTS x Accurate Online (17 Juli 2025)**  \n",
            "   - SimpliDOTS sedang mengembangkan integrasi dengan Accurate Online untuk fitur Sales Invoice (Faktur Penjualan).  \n",
            "   - Tujuan fitur ini adalah mempermudah proses penagihan tanpa perlu input manual di dua tempat.  \n",
            "   - Fitur ini masih dalam tahap BETA, dan koneksi ke sistem pembayaran (Customer Payment) belum tersedia.  \n",
            "   - Pengguna dapat mulai mencoba fitur ini dan memberikan masukan.\n",
            "\n",
            "Tidak ada informasi tambahan untuk update lainnya di tahun 2025 dalam konteks ini.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_UQxuxg0pKQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}